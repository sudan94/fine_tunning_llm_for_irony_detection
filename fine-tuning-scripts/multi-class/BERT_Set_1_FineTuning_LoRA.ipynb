{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"smZAvuwTRs3v"},"outputs":[],"source":["!pip install datasets\n","!pip install peft\n","!pip install evaluate\n","!pip install -U \"huggingface_hub[cli]\"\n","! pip install -U accelerate\n","! pip install -U transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nHI_3okURigd"},"outputs":[],"source":["from datasets import load_dataset, DatasetDict, Dataset\n","\n","from transformers import (\n","    AutoTokenizer,\n","    AutoConfig,\n","    AutoModelForSequenceClassification,\n","    DataCollatorWithPadding,\n","    TrainingArguments,\n","    Trainer)\n","\n","from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n","import evaluate\n","import torch\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B0HMOxSX0A-M"},"outputs":[],"source":["!huggingface-cli login"]},{"cell_type":"markdown","metadata":{"id":"glO5VLLAV6kj"},"source":["# dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MRnSWdB1g4ah"},"outputs":[],"source":["# sst2\n","# The Stanford Sentiment Treebank consists of sentences from movie reviews and human annotations of their sentiment. The task is to predict the sentiment of a given sentence. It uses the two-way (positive/negative) class split, with only sentence-level labels.\n","# dataset = load_dataset('csv', data_dir='/sem.csv', split='train')\n","dataset = load_dataset(\"sudan94/SemEvalEmoji2018\")\n","dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wnfwkc9VSVHc"},"outputs":[],"source":["# display % of training data with label=1\n","np.array(dataset['train']['label']).sum()/len(dataset['train']['label'])"]},{"cell_type":"markdown","metadata":{"id":"9w7RcqFVV-hI"},"source":["# model"]},{"cell_type":"markdown","metadata":{"id":"EDSYlcyfxR-r"},"source":["In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you are supplying to the from_pretrained method.\n","\n","AutoClasses are here to do this job for you so that you automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary:\n","\n","Instantiating one of AutoModel, AutoConfig and AutoTokenizer will directly create a class of the relevant architecture (ex: model = AutoModel.from_pretrained('bert-base-cased') will create a instance of BertModel)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ptr7HbwqSsa0"},"outputs":[],"source":["model_checkpoint = 'google-bert/bert-large-cased'\n","\n","# define label maps\n","id2label = {0: \"non_ironic\", 1: \"verbal_irony_polarity_contrast\",2:\"situational_irony\",3:\"verbal_irony\"}\n","label2id = {\"non_ironic\":0, \"verbal_irony_polarity_contrast\":1,\"situational_irony\":2,\"verbal_irony\":3}\n","\n","# generate classification model from model_checkpoint\n","model = AutoModelForSequenceClassification.from_pretrained(\n","    model_checkpoint, num_labels=4, id2label=id2label, label2id=label2id)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8vnFth_CS0Ec"},"outputs":[],"source":["# display architecture\n","model"]},{"cell_type":"markdown","metadata":{"id":"a8az9-hQWCFo"},"source":["# preprocess data"]},{"cell_type":"markdown","metadata":{"id":"q9EG4dxxyGZy"},"source":["Tokenization is a critical first step in preparing data for Large Language Models (LLMs) because these models don't understand raw text; they process numerical data. The tokenizer's role is to convert text into numbers that the model can understand."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DpL518OqS3ik"},"outputs":[],"source":["# create tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)\n","\n","# add pad token if none exists\n","# Pad Token (pad_token): In NLP, padding is used to ensure that all sequences (like sentences or paragraphs) are of the same length when feeding them into a model.\n","if tokenizer.pad_token is None:\n","    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n","    model.resize_token_embeddings(len(tokenizer))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h6TUa-tWS6k-"},"outputs":[],"source":["# create tokenize function\n","def tokenize_function(examples):\n","    # extract text\n","    text = examples[\"tweet\"]\n","\n","    #tokenize and truncate text\n","    tokenizer.truncation_side = \"left\"\n","    tokenized_inputs = tokenizer(\n","        text, #actual text\n","        return_tensors=\"np\", # return type numpy array\n","        truncation=True, #Indicates that truncation should be applied based on the specified parameters\n","        max_length=512 #Specifies the maximum length of the tokenized sequence\n","    )\n","\n","    return tokenized_inputs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sR3wMZh8S8qN"},"outputs":[],"source":["# tokenize training and validation datasets\n","tokenized_dataset = dataset.map(tokenize_function, batched=True)\n","tokenized_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_sx23oGyS-7t"},"outputs":[],"source":["# create data collator\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"]},{"cell_type":"markdown","metadata":{"id":"t3ja7mzQWFSP"},"source":["# evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FVWbfqUOTDgd"},"outputs":[],"source":["# import accuracy evaluation metric\n","accuracy = evaluate.load(\"accuracy\")\n","f1_metric = evaluate.load(\"f1\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RgmOWB1tTF8N"},"outputs":[],"source":["# define an evaluation function to pass into trainer later\n","def compute_metrics(p):\n","    predictions, labels = p\n","    predictions = np.argmax(predictions, axis=1)\n","    accuray = accuracy.compute(predictions=predictions, references=labels)\n","    f1 = f1_metric.compute(predictions=predictions, references=labels, average='weighted')\n","    # print(accuracy)\n","\n","    return {\"accuray\": accuray['accuracy'], \"f1\": f1['f1']}\n","\n","    # return {\"accuracy\":accuracy.compute(predictions=predictions, references=labels), \"f1\":f1_metric.compute(predictions=predictions, references=labels,average=\"macro\")}"]},{"cell_type":"markdown","metadata":{"id":"89YKx-izWITj"},"source":["# Apply untrained model to text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j0_AokiaTIL-"},"outputs":[],"source":["# define list of examples\n","text_list = dataset[\"test\"][\"tweet\"]\n","ground_truth = dataset[\"test\"][\"label\"]\n","# Initialize a list to store the table data\n","table_data = []\n","i = 0\n","for text in text_list:\n","    # tokenize text\n","    inputs = tokenizer.encode(text, return_tensors=\"pt\")\n","    # compute logits\n","    logits = model(inputs).logits\n","    # convert logits to label\n","    predictions = torch.argmax(logits)\n","    # print(predictions.tolist())\n","\n","     # Get the label string\n","    predicted_label = id2label[predictions.tolist()]\n","    # Append the text and predicted label to the table data\n","    table_data.append([text, predicted_label,predictions.tolist(), ground_truth[i]])\n","    i+=1\n","\n","    # print(text + \" - \" + id2label[predictions.tolist()])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YotA_FtEotz7"},"outputs":[],"source":["# print(table_data)\n","import pandas as pd\n","df = pd.DataFrame(table_data,columns =['tweet','predicted_class','predicted_label','actual_label'])\n","df.head(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TxVQNb7IQEXX"},"outputs":[],"source":["# from tabulate import tabulate\n","# print(\"Untrained model predictions:\")\n","# print(\"----------------------------\")\n","# print(tabulate(table_data, headers=[\"tweet\", \"predicted_class\", \"predicted_label\" ,\"actual_label\"], tablefmt=\"grid\"))"]},{"cell_type":"markdown","metadata":{"id":"wJrM1bO8WLte"},"source":["# Train model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aEWCGKLbTLxV"},"outputs":[],"source":["peft_config = LoraConfig(task_type=\"SEQ_CLS\",\n","                        r=64,\n","                        lora_alpha=16,\n","                        lora_dropout=0.1, # dropot rate for avoiding overfitting\n","                        target_modules = ['query'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uEFKNTLKTPAl"},"outputs":[],"source":["peft_config"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yaFePuyZTQil"},"outputs":[],"source":["model = get_peft_model(model, peft_config)\n","model.print_trainable_parameters()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bWHSqHIITSNt"},"outputs":[],"source":["# hyperparameters\n","lr = 1e-3\n","batch_size = 16\n","num_epochs = 10\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9IjsJpqDTUHO"},"outputs":[],"source":["# define training arguments\n","training_args = TrainingArguments(\n","    output_dir= model_checkpoint + \"-lora-text-classification\",\n","    logging_steps = 231,\n","    learning_rate=lr,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    num_train_epochs=num_epochs,\n","    weight_decay=0.01,\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    load_best_model_at_end=True,\n","    metric_for_best_model = 'eval_f1',\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RtM0djTaTWHV"},"outputs":[],"source":["# creater trainer object\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_dataset[\"train\"],\n","    eval_dataset=tokenized_dataset[\"validation\"],\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n",")\n","\n","# train model\n","trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"5Tg5iEnNWQsm"},"source":["# Generate prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T_7pWg1esNJv"},"outputs":[],"source":["f = open(\"trainer-output.txt\", \"w\")\n","f.write(str(trainer.state))\n","f.close()\n","trainer.state"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3i0MiZm2Vqi9"},"outputs":[],"source":["model.to('cpu')\n","# Initialize a list to store the table data\n","table_data = []\n","i=0\n","print(\"Trained model predictions:\")\n","print(\"--------------------------\")\n","for text in text_list:\n","    inputs = tokenizer.encode(text, return_tensors=\"pt\").to(\"cpu\")\n","\n","    logits = model(inputs).logits\n","    predictions = torch.max(logits,1).indices\n","\n","    # Get the label string\n","    predicted_label = id2label[predictions.tolist()[0]]\n","    # Append the text and predicted label to the table data\n","    table_data.append((text, predicted_label,predictions.tolist()[0], ground_truth[i]))\n","    i+=1\n","\n","    # print(text + \" - \" + id2label[predictions.tolist()[0]])\n","tuned_df = pd.DataFrame(table_data,columns =['tweet','predicted_class','predicted_label','actual_label'])\n","tuned_df.head(5)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UBnMmWSruSEy"},"outputs":[],"source":["nottuned = \"nottuned_result_bert_set1_lora.csv\"\n","finetuned = \"finetuned_result_bert_set1_lora.csv\"\n","\n","df.to_csv(nottuned,  encoding='utf-8')\n","tuned_df.to_csv(finetuned, encoding='utf-8')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hV89O5YuXwPE"},"outputs":[],"source":["# model.save_pretrained('fine_tuned_model')"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1KFwEQ0FugYT5BqMZAfBapcfvjCnYxeIg","timestamp":1703599828744},{"file_id":"https://github.com/fshnkarimi/Fine-tuning-an-LLM-using-LoRA/blob/main/FineTuning_LoRA.ipynb","timestamp":1703591421801}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}